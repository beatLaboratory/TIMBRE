{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntlh4yQ_6kPg"
   },
   "source": [
    "#Create toy data\n",
    "\n",
    "We will create a simulation of brain waves. Such data might arise when when using multiple electrodes to record electrical brain waves over a period of time. Specifically, we are simulating two different conditions, each of which leads to a different pattern of wave propagation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "AWc6SK37fhJK",
    "outputId": "5b62e219-89f4-4f64-ff92-59803abd06e3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "T = 5  # trial length in seconds\n",
    "fs = 20  # sampling rate in Hz\n",
    "f = 1  # wave frequency in Hz\n",
    "t = np.linspace(0, T, T * fs, endpoint=False)\n",
    "wave = np.exp(1j * 2 * np.pi * f * t)  # an oscillation in time\n",
    "n_channels = 10\n",
    "p1 = np.exp(1j * np.linspace(0, np.pi * 2, n_channels, endpoint=False))  # Create phase delays across electrodes (pattern 1)\n",
    "p2 = np.exp(1j * np.linspace(0, -np.pi * 2, n_channels, endpoint=False))  # Create phase delays across electrodes (pattern 2)\n",
    "p1 = p1 / np.linalg.norm(p1)\n",
    "p2 = p2 / np.linalg.norm(p2)\n",
    "\n",
    "data = np.vstack((np.outer(wave, p1), np.outer(wave, p2)))  # concatenate two different patterns of wave propagation into a single data set.\n",
    "data = data + (np.random.randn(data.shape[0], data.shape[1]) + 1j * np.random.randn(data.shape[0], data.shape[1])) / 10  # add complex-valued noise\n",
    "labels = np.hstack((np.zeros(t.size), np.ones(t.size)))  # label samples for each condition as 0 and 1, respectively\n",
    "inds_train = np.hstack((t < 4, t < 4))  # define train indices corresponding to the first 80% of each condition\n",
    "inds_test = ~inds_train  # define test indices corresponding to the last 20% of each condition\n",
    "\n",
    "proj1 = data @ p1.conj()  # project data onto p1. Remember to take p1's conjugate\n",
    "proj2 = data @ p2.conj()  # project data onto p1. Remember to take p2's conjugate\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=[10, 5]);\n",
    "\n",
    "axs[0].imshow(data.real.T, aspect='auto');\n",
    "axs[0].set_ylabel('Channel #');\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_yticks([0, n_channels - 1])\n",
    "axs[0].set_title('Data');\n",
    "# axs[0].set_ylabel('Time step');\n",
    "axs[1].plot(proj1.real, 'b');  # Plot the real component of proj1\n",
    "axs[1].plot(proj1.imag, 'b--');  # Plot the imaginary component of proj1\n",
    "axs[1].plot(np.abs(proj1), 'r');  # Plot the magnitude of proj1\n",
    "axs[1].autoscale(enable=True, axis='both', tight=True)\n",
    "axs[1].legend(['Real', 'Imag', 'Abs'], loc='right')\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_title('Pattern 1 projection');\n",
    "axs[2].plot(proj2.real, 'b');  # Plot the real component of proj2\n",
    "axs[2].plot(proj2.imag, 'b--');  # Plot the imaginary component of proj2\n",
    "axs[2].plot(np.abs(proj2), 'r');  # Plot the magnitude of proj2\n",
    "axs[2].autoscale(enable=True, axis='both', tight=True)\n",
    "axs[2].set_xlabel('Time step');\n",
    "axs[2].set_title('Pattern 2 projection');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc5DPl8SiKDC"
   },
   "source": [
    "# Install TIMBRE\n",
    "\n",
    "Now, we will create a neural network (named TIMBRE) that learns multi-channel patterns in data that best predict the label associated with each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "R_nLqGfi_mQ5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/infin/Box/college/TIMBRE/TIMBRE\n",
      "Collecting tensorflow>=2.0.0 (from beatLab==0.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/55/d1/a3631a36859ee324e1767fa7554fdf7af17965571d8537b20b311b76bcfe/tensorflow-2.11.0-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: pandas in c:\\users\\infin\\anaconda3\\lib\\site-packages (from beatLab==0.1) (0.24.2)\n",
      "Collecting hdf5storage (from beatLab==0.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/ec/29/ed9f2df3e77400b5312787b4ade31791e8eca91a39a7ccd80677490f4ea5/hdf5storage-0.1.19-py2.py3-none-any.whl (53kB)\n",
      "Collecting numpy==1.26.4 (from beatLab==0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement numpy==1.26.4 (from beatLab==0.1) (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6)\n",
      "ERROR: No matching distribution found for numpy==1.26.4 (from beatLab==0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -e TIMBRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgEqMVu5iPve"
   },
   "source": [
    "# Run TIMBRE on simulated data\n",
    "\n",
    "We will train the network. By defaut, the network has one node per class. Since there are two classes, there are two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "imPBrbNwMhkX"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9e23ff8ed67a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mTIMBRE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTIMBRE\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTIMBRE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTIMBRE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minds_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minds_train\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# train neural network without hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Box\\college\\TIMBRE\\TIMBRE.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mGautam\u001b[0m \u001b[0mAgarwal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\"\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomplexnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from TIMBRE.TIMBRE import TIMBRE\n",
    "\n",
    "m, fm, _ = TIMBRE(data, labels, inds_test, inds_train)  # train neural network without hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPVvGHMoisap"
   },
   "source": [
    "#Examine performance\n",
    "\n",
    "We will observe how the network's performance improves during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "ozX-zHp8i_Nb",
    "outputId": "f2ad43b6-13f2-4edd-9647-e3367d4f74ef"
   },
   "outputs": [],
   "source": [
    "from TIMBRE.helpers import layer_output\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(10,5));\n",
    "axs[0].plot(fm.history['accuracy']);\n",
    "axs[0].plot(fm.history['val_accuracy']);\n",
    "axs[0].legend(['Train', 'Test']);\n",
    "axs[0].set_title('Accuracy');\n",
    "axs[0].set_xlabel('Training epoch');\n",
    "axs[1].plot(fm.history['loss']);\n",
    "axs[1].plot(fm.history['val_loss']);\n",
    "axs[1].legend(['Train', 'Test']);\n",
    "axs[1].set_title('Loss');\n",
    "axs[1].set_xlabel('Training epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhgQBBzjhCEL"
   },
   "source": [
    "# Visualize network activity\n",
    "\n",
    "Finally, we visualize the response of the trained model's layers to the input:\n",
    "1.  **Complex-valued projection of the input.** Note that each of the two nodes learns one of the two patterns present in the data.\n",
    "2.  **Amplitude of the projection.** This discards the phase of the projection, so we know how much of each pattern is present.\n",
    "3.  **Softmax of the amplitude.** This converts the response to a probability distribution that sums to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "KbEiqsjEg1PJ",
    "outputId": "7d70d0d1-2111-4e86-c6cc-59e65b6f3981"
   },
   "outputs": [],
   "source": [
    "titles = ['Projection', 'Amplitude', 'Softmax', 'Softmax 2'];\n",
    "fig1, axs1 = plt.subplots(1, len(m.layers), figsize=(20, 5));\n",
    "styles = ['b', 'r', 'b--', 'r--']\n",
    "X = np.concatenate((np.real(data), np.imag(data)), axis=1)  # preprocess\n",
    "for i in range(len(m.layers)):  # plot the output of each layer in network\n",
    "    pr = layer_output(data, m, i)\n",
    "    for j in range(pr.shape[1]):\n",
    "        axs1[i].plot(pr[:, j], styles[j]);\n",
    "    axs1[i].set_title(titles[i]);\n",
    "    axs1[i].set_xlabel('Time step');\n",
    "    axs1[i].autoscale(enable=True, axis='both', tight=True);\n",
    "\n",
    "axs1[0].legend(['Node 1 (real)', 'Node 2 (real)', 'Node 1 (imag)', 'Node 2 (imag)']);\n",
    "axs1[1].legend(['Node 1', 'Node 2']);\n",
    "axs1[2].legend(['Node 1', 'Node 2']);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
