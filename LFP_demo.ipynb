{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQv9erofzetWG0zejE80qD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beatLaboratory/TIMBRE/blob/main/LFP_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Description\n",
        "\n",
        "In this notebook we import the experimental data and use LFP and spikes to predict which maze arm the rat is occupying.\n",
        "\n",
        "First, let's install the dependencies."
      ],
      "metadata": {
        "id": "4Iz9JqoFO13E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/beatLaboratory/TIMBRE.git\n",
        "!pip install -r TIMBRE/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20Eq5x4GO1Oa",
        "outputId": "becce9c6-5140-405b-cb98-0d7ce84628f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TIMBRE'...\n",
            "remote: Enumerating objects: 140, done.\u001b[K\n",
            "remote: Counting objects: 100% (140/140), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 140 (delta 80), reused 65 (delta 29), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (140/140), 3.08 MiB | 6.53 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "Collecting keras-complex (from -r TIMBRE/requirements.txt (line 1))\n",
            "  Downloading keras_complex-0.2.3-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: tensorflow>=\"2.0.0\" in /usr/local/lib/python3.10/dist-packages (from keras-complex->-r TIMBRE/requirements.txt (line 1)) (2.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (2.15.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->keras-complex->-r TIMBRE/requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=\"2.0.0\"->keras-complex->-r TIMBRE/requirements.txt (line 1)) (3.2.2)\n",
            "Installing collected packages: keras-complex\n",
            "Successfully installed keras-complex-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and evaluate models\n",
        "\n",
        "Now we will get the data for one session and train three classifiers:\n",
        "1.   Linear classifier trained on the demodulated LFP.\n",
        "2.   TIMBRE - a complex-valued neural network for identifying phase-amplitude patterns in the LFP.\n",
        "3.   Linear classifier trained on the firing rates of the neurons that were simultaneously recorded.\n",
        "\n",
        "Here we use session 4, which has less data so downloads and runs faster."
      ],
      "metadata": {
        "id": "rakgNSQORDff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poPr_-q8OvCi",
        "outputId": "e8b69c72-7b73-4270-ce7e-f80c837a4427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading file: data04.mat\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "from scipy import io\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import TIMBRE.helpers as helpers\n",
        "\n",
        "repository_id = \"24757638\" #Behavior_and_spiking_data_for_rats_running_a_3-arm_maze\n",
        "url = f\"https://api.figshare.com/v2/articles/{repository_id}\"\n",
        "\n",
        "# Make the API request\n",
        "response = requests.get(url)\n",
        "files = response.json()['files']\n",
        "\n",
        "file_pattern = \"data04.mat\"\n",
        "\n",
        "# Find the matching files\n",
        "file = next((file for file in files if file['name'] == file_pattern), None)\n",
        "# Download the files using wget\n",
        "print(f\"Downloading file: {file['name']}\")\n",
        "os.system(f\"wget -O {'data.mat'} {file['download_url']}\")\n",
        "data = io.loadmat('data.mat')\n",
        "LFPs = helpers.filter_data(data['lfps'],2,fs=25,use_hilbert=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_folds = 5 #how many folds to split data into\n",
        "run_folds = 1 #how many folds to train\n",
        "all_scores = np.zeros((3,2,run_folds))\n",
        "for i in range(run_folds):#n_folds):\n",
        "  for j in range(1):#2):\n",
        "    test_inds, train_inds = helpers.test_train(data['lapID'],j+1,n_folds,i) #only test 1 fold per session\n",
        "    model_sp = LogisticRegression()\n",
        "    model_sp.fit(data['spikes'][train_inds],data['lapID'][train_inds,1])\n",
        "    all_scores[2,j,i] = np.mean(data['lapID'][test_inds,1] == model_sp.predict(data['spikes'][test_inds]))\n",
        "    wLFPs,_,_ = helpers.whiten(LFPs,train_inds)\n",
        "    #model_lfp, fm = helpers.TIMBRE(wLFPs,data['lapID'][:,1],test_inds,train_inds,3*2**3) #8 hidden nodes per arm\n",
        "    #all_scores[1,j,i] = fm.history['val_accuracy'][-1] #the accuracy on test data after training\n",
        "    model_lfp_demod, fm = carrier_based(wLFPs,data['lapID'][:,1],test_inds,train_inds)\n",
        "    all_scores[0,j,i] = fm.history['val_accuracy'][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCi4omQrhfDg",
        "outputId": "e258125c-0341-4db6-de3a-1904a8d62d52"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "75/75 - 1s - loss: 1.0831 - accuracy: 0.5004 - val_loss: 1.0522 - val_accuracy: 0.7268 - 960ms/epoch - 13ms/step\n",
            "Epoch 2/100\n",
            "75/75 - 0s - loss: 1.0341 - accuracy: 0.8413 - val_loss: 1.0057 - val_accuracy: 0.8793 - 214ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "75/75 - 0s - loss: 0.9812 - accuracy: 0.9204 - val_loss: 0.9587 - val_accuracy: 0.9009 - 227ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "75/75 - 0s - loss: 0.9307 - accuracy: 0.9326 - val_loss: 0.9143 - val_accuracy: 0.9047 - 208ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "75/75 - 0s - loss: 0.8868 - accuracy: 0.9363 - val_loss: 0.8774 - val_accuracy: 0.9072 - 215ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "75/75 - 0s - loss: 0.8483 - accuracy: 0.9389 - val_loss: 0.8432 - val_accuracy: 0.9098 - 197ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "75/75 - 0s - loss: 0.8148 - accuracy: 0.9384 - val_loss: 0.8155 - val_accuracy: 0.9060 - 218ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "75/75 - 0s - loss: 0.7830 - accuracy: 0.9422 - val_loss: 0.7831 - val_accuracy: 0.9111 - 192ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "75/75 - 0s - loss: 0.7537 - accuracy: 0.9397 - val_loss: 0.7583 - val_accuracy: 0.9098 - 232ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "75/75 - 0s - loss: 0.7264 - accuracy: 0.9426 - val_loss: 0.7338 - val_accuracy: 0.9111 - 199ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "75/75 - 0s - loss: 0.7007 - accuracy: 0.9410 - val_loss: 0.7120 - val_accuracy: 0.9111 - 225ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "75/75 - 0s - loss: 0.6757 - accuracy: 0.9397 - val_loss: 0.6905 - val_accuracy: 0.9111 - 191ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "75/75 - 0s - loss: 0.6525 - accuracy: 0.9414 - val_loss: 0.6695 - val_accuracy: 0.9111 - 218ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "75/75 - 0s - loss: 0.6302 - accuracy: 0.9443 - val_loss: 0.6489 - val_accuracy: 0.9161 - 188ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "75/75 - 0s - loss: 0.6084 - accuracy: 0.9451 - val_loss: 0.6283 - val_accuracy: 0.9136 - 192ms/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "75/75 - 0s - loss: 0.5883 - accuracy: 0.9481 - val_loss: 0.6123 - val_accuracy: 0.9187 - 217ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "75/75 - 0s - loss: 0.5692 - accuracy: 0.9468 - val_loss: 0.5967 - val_accuracy: 0.9187 - 193ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "75/75 - 0s - loss: 0.5500 - accuracy: 0.9506 - val_loss: 0.5782 - val_accuracy: 0.9187 - 210ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "75/75 - 0s - loss: 0.5325 - accuracy: 0.9531 - val_loss: 0.5617 - val_accuracy: 0.9174 - 215ms/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "75/75 - 0s - loss: 0.5154 - accuracy: 0.9569 - val_loss: 0.5501 - val_accuracy: 0.9187 - 266ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "75/75 - 0s - loss: 0.4996 - accuracy: 0.9535 - val_loss: 0.5362 - val_accuracy: 0.9187 - 293ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "75/75 - 0s - loss: 0.4841 - accuracy: 0.9556 - val_loss: 0.5253 - val_accuracy: 0.9161 - 291ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "75/75 - 0s - loss: 0.4697 - accuracy: 0.9585 - val_loss: 0.5106 - val_accuracy: 0.9174 - 281ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "75/75 - 0s - loss: 0.4555 - accuracy: 0.9581 - val_loss: 0.5008 - val_accuracy: 0.9174 - 282ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "75/75 - 0s - loss: 0.4430 - accuracy: 0.9636 - val_loss: 0.4894 - val_accuracy: 0.9199 - 282ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "75/75 - 0s - loss: 0.4301 - accuracy: 0.9594 - val_loss: 0.4788 - val_accuracy: 0.9199 - 298ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "75/75 - 0s - loss: 0.4178 - accuracy: 0.9611 - val_loss: 0.4700 - val_accuracy: 0.9199 - 307ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "75/75 - 0s - loss: 0.4058 - accuracy: 0.9640 - val_loss: 0.4623 - val_accuracy: 0.9161 - 279ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "75/75 - 0s - loss: 0.3948 - accuracy: 0.9661 - val_loss: 0.4536 - val_accuracy: 0.9212 - 303ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "75/75 - 0s - loss: 0.3838 - accuracy: 0.9694 - val_loss: 0.4417 - val_accuracy: 0.9187 - 294ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "75/75 - 0s - loss: 0.3736 - accuracy: 0.9719 - val_loss: 0.4338 - val_accuracy: 0.9225 - 299ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "75/75 - 0s - loss: 0.3633 - accuracy: 0.9703 - val_loss: 0.4284 - val_accuracy: 0.9238 - 234ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "75/75 - 0s - loss: 0.3541 - accuracy: 0.9715 - val_loss: 0.4193 - val_accuracy: 0.9238 - 214ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "75/75 - 0s - loss: 0.3451 - accuracy: 0.9711 - val_loss: 0.4106 - val_accuracy: 0.9225 - 215ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "75/75 - 0s - loss: 0.3366 - accuracy: 0.9711 - val_loss: 0.4069 - val_accuracy: 0.9225 - 208ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "75/75 - 0s - loss: 0.3277 - accuracy: 0.9728 - val_loss: 0.3977 - val_accuracy: 0.9238 - 192ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "75/75 - 0s - loss: 0.3199 - accuracy: 0.9757 - val_loss: 0.3944 - val_accuracy: 0.9212 - 214ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "75/75 - 0s - loss: 0.3123 - accuracy: 0.9761 - val_loss: 0.3886 - val_accuracy: 0.9212 - 209ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "75/75 - 0s - loss: 0.3050 - accuracy: 0.9770 - val_loss: 0.3828 - val_accuracy: 0.9238 - 226ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "75/75 - 0s - loss: 0.2979 - accuracy: 0.9770 - val_loss: 0.3764 - val_accuracy: 0.9263 - 197ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "75/75 - 0s - loss: 0.2908 - accuracy: 0.9774 - val_loss: 0.3684 - val_accuracy: 0.9250 - 213ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "75/75 - 0s - loss: 0.2842 - accuracy: 0.9770 - val_loss: 0.3682 - val_accuracy: 0.9225 - 206ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "75/75 - 0s - loss: 0.2786 - accuracy: 0.9774 - val_loss: 0.3639 - val_accuracy: 0.9212 - 229ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "75/75 - 0s - loss: 0.2722 - accuracy: 0.9816 - val_loss: 0.3572 - val_accuracy: 0.9225 - 213ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "75/75 - 0s - loss: 0.2661 - accuracy: 0.9799 - val_loss: 0.3529 - val_accuracy: 0.9225 - 213ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "75/75 - 0s - loss: 0.2597 - accuracy: 0.9799 - val_loss: 0.3476 - val_accuracy: 0.9238 - 187ms/epoch - 2ms/step\n",
            "Epoch 47/100\n",
            "75/75 - 0s - loss: 0.2542 - accuracy: 0.9832 - val_loss: 0.3413 - val_accuracy: 0.9238 - 209ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "75/75 - 0s - loss: 0.2489 - accuracy: 0.9803 - val_loss: 0.3396 - val_accuracy: 0.9238 - 206ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "75/75 - 0s - loss: 0.2437 - accuracy: 0.9812 - val_loss: 0.3360 - val_accuracy: 0.9238 - 211ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "75/75 - 0s - loss: 0.2388 - accuracy: 0.9828 - val_loss: 0.3354 - val_accuracy: 0.9250 - 189ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "75/75 - 0s - loss: 0.2337 - accuracy: 0.9849 - val_loss: 0.3286 - val_accuracy: 0.9250 - 217ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "75/75 - 0s - loss: 0.2289 - accuracy: 0.9849 - val_loss: 0.3233 - val_accuracy: 0.9212 - 221ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "75/75 - 0s - loss: 0.2242 - accuracy: 0.9849 - val_loss: 0.3224 - val_accuracy: 0.9225 - 230ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "75/75 - 0s - loss: 0.2191 - accuracy: 0.9862 - val_loss: 0.3200 - val_accuracy: 0.9199 - 221ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "75/75 - 0s - loss: 0.2152 - accuracy: 0.9879 - val_loss: 0.3148 - val_accuracy: 0.9263 - 216ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "75/75 - 0s - loss: 0.2103 - accuracy: 0.9862 - val_loss: 0.3147 - val_accuracy: 0.9225 - 185ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "75/75 - 0s - loss: 0.2062 - accuracy: 0.9879 - val_loss: 0.3076 - val_accuracy: 0.9212 - 213ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "75/75 - 0s - loss: 0.2020 - accuracy: 0.9862 - val_loss: 0.3063 - val_accuracy: 0.9199 - 210ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "75/75 - 0s - loss: 0.1978 - accuracy: 0.9858 - val_loss: 0.3043 - val_accuracy: 0.9225 - 222ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "75/75 - 0s - loss: 0.1945 - accuracy: 0.9858 - val_loss: 0.3028 - val_accuracy: 0.9212 - 220ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "75/75 - 0s - loss: 0.1908 - accuracy: 0.9891 - val_loss: 0.2996 - val_accuracy: 0.9212 - 198ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "75/75 - 0s - loss: 0.1871 - accuracy: 0.9887 - val_loss: 0.2970 - val_accuracy: 0.9238 - 211ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "75/75 - 0s - loss: 0.1840 - accuracy: 0.9883 - val_loss: 0.2938 - val_accuracy: 0.9238 - 193ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "75/75 - 0s - loss: 0.1806 - accuracy: 0.9895 - val_loss: 0.2895 - val_accuracy: 0.9238 - 199ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "75/75 - 0s - loss: 0.1763 - accuracy: 0.9895 - val_loss: 0.2894 - val_accuracy: 0.9238 - 192ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "75/75 - 0s - loss: 0.1735 - accuracy: 0.9908 - val_loss: 0.2885 - val_accuracy: 0.9225 - 187ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "75/75 - 0s - loss: 0.1710 - accuracy: 0.9899 - val_loss: 0.2828 - val_accuracy: 0.9225 - 202ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "75/75 - 0s - loss: 0.1671 - accuracy: 0.9912 - val_loss: 0.2811 - val_accuracy: 0.9250 - 219ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "75/75 - 0s - loss: 0.1646 - accuracy: 0.9908 - val_loss: 0.2804 - val_accuracy: 0.9225 - 196ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "75/75 - 0s - loss: 0.1613 - accuracy: 0.9912 - val_loss: 0.2760 - val_accuracy: 0.9238 - 218ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "75/75 - 0s - loss: 0.1586 - accuracy: 0.9920 - val_loss: 0.2746 - val_accuracy: 0.9263 - 191ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "75/75 - 0s - loss: 0.1559 - accuracy: 0.9916 - val_loss: 0.2755 - val_accuracy: 0.9263 - 197ms/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(all_scores,axis=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PliJbrNcFJe",
        "outputId": "cd9ea431-a7cf-4384-a151-2ce6619f2ee5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.92630243 0.        ]\n",
            " [0.         0.        ]\n",
            " [0.96315121 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import sample\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import utils as np_utils\n",
        "from keras import backend, optimizers, models, constraints, layers, activations\n",
        "from keras.callbacks import EarlyStopping\n",
        "import complexnn\n",
        "\n",
        "def carrier_based(X,Y,inds_test,inds_train,learn_rate=.001,is_categorical=True):\n",
        "  \"\"\"\n",
        "  Predicts output using demodulated LFP and linear regression\n",
        "\n",
        "  Parameters:\n",
        "  - X = Multi-channel data (T samples x N channels, complex-valued)\n",
        "  - Y = Category labels (T samples, integer-valued)\n",
        "  - inds_test = test indices (Either T x 1 boolean, or U x 1 integers)\n",
        "  - inds_train = train indices (Either T x 1 boolean, or U x 1 integers)\n",
        "  - learn_rate = how quickly the network learns\n",
        "  - is_categorical = whether the output consists of discrete classes\n",
        "\n",
        "  Returns:\n",
        "  - model: trained network\n",
        "  - fittedModel: history of loss and accuracy for test and train data\n",
        "  \"\"\"\n",
        "\n",
        "  #stack the real and imaginary components of the data\n",
        "  X = X*np.exp(1j*-np.angle(X[:,0][:,np.newaxis]))\n",
        "  X = np.concatenate((np.real(X), np.imag(X)), axis = 1)\n",
        "  #use one-hot encoding for the class labels\n",
        "  if is_categorical:\n",
        "      Y = np_utils.to_categorical(Y)\n",
        "      my_loss = 'categorical_crossentropy'\n",
        "  else:\n",
        "      my_loss = 'kde'\n",
        "\n",
        "  backend.clear_session()\n",
        "  # Early Stopping: stop training model when test loss stops decreasing\n",
        "  es = EarlyStopping(monitor = 'val_loss', patience = 1)\n",
        "  # Specify the algorithm and step size used by gradient descent\n",
        "  adam = optimizers.Adam(learning_rate=learn_rate)\n",
        "  num_chans = 24\n",
        "  model = models.Sequential()\n",
        "  # Layer 1: Takes a complex-valued projection of the input\n",
        "  model.add(layers.Dense(num_chans, input_shape=(X.shape[1],), use_bias=True, kernel_constraint = constraints.unit_norm()))\n",
        "  # Layer 2: Softmax of layer 2\n",
        "  model.add(layers.Activation(activations.softmax))\n",
        "  model.add(layers.Dense(Y.shape[1],activation='softmax'))\n",
        "  model.compile(loss=my_loss, optimizer=adam,metrics = ['accuracy'])\n",
        "  # Train the model\n",
        "  fittedModel = model.fit(X[inds_train,:], Y[inds_train,:], epochs = 100,\n",
        "    verbose = 2, validation_data=(X[inds_test,:], Y[inds_test,:]),\n",
        "    shuffle=True, callbacks=[es])\n",
        "  return model, fittedModel\n",
        "\n",
        "def test_train(lapID,which_phase,n_folds = 5,which_fold = 0):\n",
        "    \"\"\"\n",
        "    Returns test and train samples\n",
        "\n",
        "    Parameters:\n",
        "    - lapID: contains info about trial number and maze arm of each sample\n",
        "    - which_phase: which phase of the session to use (see get_data\\get_behav for info)\n",
        "    - n_folds: how many folds to assign\n",
        "    - which_fold: which fold to return values for\n",
        "\n",
        "    Returns:\n",
        "    - train_inds: which samples to use for training model\n",
        "    - test_inds: which samples to use for testing model\n",
        "    \"\"\"\n",
        "    ctr = np.zeros(3)\n",
        "    use_sample = lapID[:,3] == which_phase\n",
        "    if which_phase == 2: # period where rat is staying at port\n",
        "        use_sample = use_sample & (lapID[:,2] == 1) #only use correct trials\n",
        "    fold_assign = -np.ones(np.size(use_sample))\n",
        "    for i in range(int(np.max(lapID[:,0]))):\n",
        "        inds = (lapID[:,0] == i) & use_sample\n",
        "        if np.sum(inds):\n",
        "            which_arm = int(lapID[inds,1][0])\n",
        "            fold_assign[inds] = ctr[which_arm]%n_folds\n",
        "            ctr[which_arm] += 1\n",
        "    test_inds = fold_assign == which_fold\n",
        "    train_inds = np.isin(fold_assign, np.arange(n_folds)) & ~test_inds\n",
        "    train_inds = balanced_indices(lapID[:,1],train_inds)\n",
        "\n",
        "    return test_inds, train_inds\n",
        "\n",
        "def balanced_indices(vector, bool_indices):\n",
        "\n",
        "    \"\"\"\n",
        "    Returns indices that balance the number of samples for each label in vector\n",
        "\n",
        "    Parameters:\n",
        "    vector: The input vector from which to select indices.\n",
        "    bool_indices: A boolean array indicating which indices in the vector to consider.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of indices representing a balanced selection of the unique values in the subset of the vector.\n",
        "\n",
        "    Generated using ChatGPT\n",
        "    \"\"\"\n",
        "    # Convert boolean indices to actual indices\n",
        "    actual_indices = np.where(bool_indices)[0]\n",
        "\n",
        "    # Extract the elements and their corresponding indices\n",
        "    selected_elements = [(vector[i], i) for i in actual_indices]\n",
        "\n",
        "    # Find unique elements\n",
        "    unique_elements = np.unique(vector[bool_indices])\n",
        "\n",
        "    # Group elements by value and collect their indices\n",
        "    elements_indices = {element: [] for element in unique_elements}\n",
        "    for value, idx in selected_elements:\n",
        "        if value in elements_indices:\n",
        "            elements_indices[value].append(idx)\n",
        "\n",
        "    # Find the minimum count among the unique elements\n",
        "    min_count = min(len(elements_indices[element]) for element in unique_elements)\n",
        "\n",
        "    # Create a balanced set of indices\n",
        "    balanced_indices_set = []\n",
        "    for element in unique_elements:\n",
        "        if len(elements_indices[element]) >= min_count:\n",
        "            balanced_indices_set.extend(sample(elements_indices[element], min_count))\n",
        "\n",
        "    return np.array(balanced_indices_set)"
      ],
      "metadata": {
        "id": "poJvsPBQNhnu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eMFNCagDNhWm"
      }
    }
  ]
}